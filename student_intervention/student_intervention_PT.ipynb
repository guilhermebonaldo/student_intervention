{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Nanodegree Engenheiro de Machine Learning\n",
    "## Aprendizagem Supervisionada\n",
    "## Projeto 2: Construindo um Sistema de Intervenção para Estudantes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Bem-vindo ao segundo projeto do Nanodegree de Machine Learning! Neste Notebook, alguns templates de código já foram fornecidos, e será o seu trabalho implementar funcionalidades necessárias para completar este projeto com êxito. Seções que começam com **'Implementação'** no cabeçalho indicam que o bloco de código que se segue precisará de funcionalidades adicionais que você deve fornecer. Instruções serão providenciadas para cada seção e as especificações para cada implementação estarão marcadas no bloco de código com o comando `'TODO'`. Tenha certeza de ler atentamente todas as instruções!\n",
    "\n",
    "Além do código implementado, haverá questões relacionadas ao projeto e à implementação que você deve responder. Cada seção em que você tem que responder uma questão será antecedida de um cabeçalho **'Questão X'**. Leia atentamente cada questão e escreva respostas completas nas caixas de texto subsequentes que começam com **'Resposta: '**. O projeto enviado será avaliado baseado nas respostas para cada questão e a implementação que você forneceu.  \n",
    "\n",
    ">**Nota:** Células de código e Markdown podem ser executadas utilizando o atalho de teclado **Shift + Enter**. Além disso, as células Markdown podem ser editadas, um clique duplo na célula entra no modo de edição."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Questão 1 - Classificação versus Regressão\n",
    "*Seu objetivo neste projeto é identificar estudantes que possam precisar de intervenção antecipada antes de serem reprovados. Que tipo de problema de aprendizagem supervisionada é esse: classificação ou regressão? Por quê?*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Resposta: ** Este é um problema de classificação, pois irá classificar os estudantes em dois grupos: os que precisam de intervenção e os que não precisam"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Observando os Dados\n",
    "Execute a célula de código abaixo para carregar as bibliotecas de Python necessárias e os dados sobre os estudantes. Note que a última coluna desse conjunto de dados, `'passed'`, será nosso rótulo alvo (se o aluno foi ou não aprovado). As outras colunas são atributos sobre cada aluno."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Os dados dos estudantes foram lidos com êxito!\n"
     ]
    }
   ],
   "source": [
    "# Importar bibliotecas\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "from time import time\n",
    "from sklearn.metrics import f1_score\n",
    "\n",
    "# Ler os dados dos estudantes\n",
    "student_data = pd.read_csv(\"student-data.csv\")\n",
    "print \"Os dados dos estudantes foram lidos com êxito!\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Implementação: Observando os Dados\n",
    "Vamos começar observando o conjunto de dados para determinar quantos são os estudantes sobre os quais temos informações e entender a taxa de graduação entre esses estudantes. Na célula de código abaixo, você vai precisar calcular o seguinte:\n",
    "- O número total de estudantes, `n_students`.\n",
    "- O número total de atributos para cada estudante, `n_features`.\n",
    "- O número de estudantes aprovados, `n_passed`.\n",
    "- O número de estudantes reprovados, `n_failed`.\n",
    "- A taxa de graduação da classe, `grad_rate`, em porcentagem (%).\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>school</th>\n",
       "      <th>sex</th>\n",
       "      <th>age</th>\n",
       "      <th>address</th>\n",
       "      <th>famsize</th>\n",
       "      <th>Pstatus</th>\n",
       "      <th>Medu</th>\n",
       "      <th>Fedu</th>\n",
       "      <th>Mjob</th>\n",
       "      <th>Fjob</th>\n",
       "      <th>...</th>\n",
       "      <th>internet</th>\n",
       "      <th>romantic</th>\n",
       "      <th>famrel</th>\n",
       "      <th>freetime</th>\n",
       "      <th>goout</th>\n",
       "      <th>Dalc</th>\n",
       "      <th>Walc</th>\n",
       "      <th>health</th>\n",
       "      <th>absences</th>\n",
       "      <th>passed</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>GP</td>\n",
       "      <td>F</td>\n",
       "      <td>18</td>\n",
       "      <td>U</td>\n",
       "      <td>GT3</td>\n",
       "      <td>A</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>at_home</td>\n",
       "      <td>teacher</td>\n",
       "      <td>...</td>\n",
       "      <td>no</td>\n",
       "      <td>no</td>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>6</td>\n",
       "      <td>no</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>GP</td>\n",
       "      <td>F</td>\n",
       "      <td>17</td>\n",
       "      <td>U</td>\n",
       "      <td>GT3</td>\n",
       "      <td>T</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>at_home</td>\n",
       "      <td>other</td>\n",
       "      <td>...</td>\n",
       "      <td>yes</td>\n",
       "      <td>no</td>\n",
       "      <td>5</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>no</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>GP</td>\n",
       "      <td>F</td>\n",
       "      <td>15</td>\n",
       "      <td>U</td>\n",
       "      <td>LE3</td>\n",
       "      <td>T</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>at_home</td>\n",
       "      <td>other</td>\n",
       "      <td>...</td>\n",
       "      <td>yes</td>\n",
       "      <td>no</td>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>10</td>\n",
       "      <td>yes</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>GP</td>\n",
       "      <td>F</td>\n",
       "      <td>15</td>\n",
       "      <td>U</td>\n",
       "      <td>GT3</td>\n",
       "      <td>T</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>health</td>\n",
       "      <td>services</td>\n",
       "      <td>...</td>\n",
       "      <td>yes</td>\n",
       "      <td>yes</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>2</td>\n",
       "      <td>yes</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>GP</td>\n",
       "      <td>F</td>\n",
       "      <td>16</td>\n",
       "      <td>U</td>\n",
       "      <td>GT3</td>\n",
       "      <td>T</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>other</td>\n",
       "      <td>other</td>\n",
       "      <td>...</td>\n",
       "      <td>no</td>\n",
       "      <td>no</td>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>5</td>\n",
       "      <td>4</td>\n",
       "      <td>yes</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 31 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "  school sex  age address famsize Pstatus  Medu  Fedu     Mjob      Fjob  \\\n",
       "0     GP   F   18       U     GT3       A     4     4  at_home   teacher   \n",
       "1     GP   F   17       U     GT3       T     1     1  at_home     other   \n",
       "2     GP   F   15       U     LE3       T     1     1  at_home     other   \n",
       "3     GP   F   15       U     GT3       T     4     2   health  services   \n",
       "4     GP   F   16       U     GT3       T     3     3    other     other   \n",
       "\n",
       "   ...   internet romantic  famrel  freetime  goout Dalc Walc health absences  \\\n",
       "0  ...         no       no       4         3      4    1    1      3        6   \n",
       "1  ...        yes       no       5         3      3    1    1      3        4   \n",
       "2  ...        yes       no       4         3      2    2    3      3       10   \n",
       "3  ...        yes      yes       3         2      2    1    1      5        2   \n",
       "4  ...         no       no       4         3      2    1    2      5        4   \n",
       "\n",
       "  passed  \n",
       "0     no  \n",
       "1     no  \n",
       "2    yes  \n",
       "3    yes  \n",
       "4    yes  \n",
       "\n",
       "[5 rows x 31 columns]"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "student_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>age</th>\n",
       "      <th>Medu</th>\n",
       "      <th>Fedu</th>\n",
       "      <th>traveltime</th>\n",
       "      <th>studytime</th>\n",
       "      <th>failures</th>\n",
       "      <th>famrel</th>\n",
       "      <th>freetime</th>\n",
       "      <th>goout</th>\n",
       "      <th>Dalc</th>\n",
       "      <th>Walc</th>\n",
       "      <th>health</th>\n",
       "      <th>absences</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>395.000000</td>\n",
       "      <td>395.000000</td>\n",
       "      <td>395.000000</td>\n",
       "      <td>395.000000</td>\n",
       "      <td>395.000000</td>\n",
       "      <td>395.000000</td>\n",
       "      <td>395.000000</td>\n",
       "      <td>395.000000</td>\n",
       "      <td>395.000000</td>\n",
       "      <td>395.000000</td>\n",
       "      <td>395.000000</td>\n",
       "      <td>395.000000</td>\n",
       "      <td>395.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>16.696203</td>\n",
       "      <td>2.749367</td>\n",
       "      <td>2.521519</td>\n",
       "      <td>1.448101</td>\n",
       "      <td>2.035443</td>\n",
       "      <td>0.334177</td>\n",
       "      <td>3.944304</td>\n",
       "      <td>3.235443</td>\n",
       "      <td>3.108861</td>\n",
       "      <td>1.481013</td>\n",
       "      <td>2.291139</td>\n",
       "      <td>3.554430</td>\n",
       "      <td>5.708861</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>1.276043</td>\n",
       "      <td>1.094735</td>\n",
       "      <td>1.088201</td>\n",
       "      <td>0.697505</td>\n",
       "      <td>0.839240</td>\n",
       "      <td>0.743651</td>\n",
       "      <td>0.896659</td>\n",
       "      <td>0.998862</td>\n",
       "      <td>1.113278</td>\n",
       "      <td>0.890741</td>\n",
       "      <td>1.287897</td>\n",
       "      <td>1.390303</td>\n",
       "      <td>8.003096</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>15.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>16.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>17.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>4.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>18.000000</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>8.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>22.000000</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>75.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              age        Medu        Fedu  traveltime   studytime    failures  \\\n",
       "count  395.000000  395.000000  395.000000  395.000000  395.000000  395.000000   \n",
       "mean    16.696203    2.749367    2.521519    1.448101    2.035443    0.334177   \n",
       "std      1.276043    1.094735    1.088201    0.697505    0.839240    0.743651   \n",
       "min     15.000000    0.000000    0.000000    1.000000    1.000000    0.000000   \n",
       "25%     16.000000    2.000000    2.000000    1.000000    1.000000    0.000000   \n",
       "50%     17.000000    3.000000    2.000000    1.000000    2.000000    0.000000   \n",
       "75%     18.000000    4.000000    3.000000    2.000000    2.000000    0.000000   \n",
       "max     22.000000    4.000000    4.000000    4.000000    4.000000    3.000000   \n",
       "\n",
       "           famrel    freetime       goout        Dalc        Walc      health  \\\n",
       "count  395.000000  395.000000  395.000000  395.000000  395.000000  395.000000   \n",
       "mean     3.944304    3.235443    3.108861    1.481013    2.291139    3.554430   \n",
       "std      0.896659    0.998862    1.113278    0.890741    1.287897    1.390303   \n",
       "min      1.000000    1.000000    1.000000    1.000000    1.000000    1.000000   \n",
       "25%      4.000000    3.000000    2.000000    1.000000    1.000000    3.000000   \n",
       "50%      4.000000    3.000000    3.000000    1.000000    2.000000    4.000000   \n",
       "75%      5.000000    4.000000    4.000000    2.000000    3.000000    5.000000   \n",
       "max      5.000000    5.000000    5.000000    5.000000    5.000000    5.000000   \n",
       "\n",
       "         absences  \n",
       "count  395.000000  \n",
       "mean     5.708861  \n",
       "std      8.003096  \n",
       "min      0.000000  \n",
       "25%      0.000000  \n",
       "50%      4.000000  \n",
       "75%      8.000000  \n",
       "max     75.000000  "
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "student_data.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Análise Gráfica"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Número total de estudantes: 395\n",
      "Número de atributos: 30\n",
      "Número de estudantes aprovados: 265\n",
      "Número de estudantes reprovados: 130\n",
      "Taxa de graduação: 67.09%\n"
     ]
    }
   ],
   "source": [
    "# TODO: Calcule o número de estudante\n",
    "n_students = len(student_data)\n",
    "\n",
    "# TODO: Calcule o número de atributos\n",
    "n_features = len(student_data.columns)-1\n",
    "\n",
    "# TODO: Calcule o número de alunos aprovados\n",
    "n_passed = len(student_data[student_data.passed == 'yes'])\n",
    "\n",
    "# TODO: Calcule o número de alunos reprovados\n",
    "n_failed = len(student_data[student_data.passed == 'no'])\n",
    "\n",
    "# TODO: Calcule a taxa de graduação\n",
    "grad_rate = float(n_passed)/n_students*100\n",
    "\n",
    "# Imprima os resultados\n",
    "print \"Número total de estudantes: {}\".format(n_students)\n",
    "print \"Número de atributos: {}\".format(n_features)\n",
    "print \"Número de estudantes aprovados: {}\".format(n_passed)\n",
    "print \"Número de estudantes reprovados: {}\".format(n_failed)\n",
    "print \"Taxa de graduação: {:.2f}%\".format(grad_rate)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preparando os Dados\n",
    "Nesta seção, vamos preparara os dados para modelagem, treinamento e teste.\n",
    "\n",
    "### Identificar atributos e variáveis-alvo\n",
    "É comum que os dados que você obteve contenham atributos não numéricos. Isso pode ser um problema, dado que a maioria dos algoritmos de machine learning esperam dados númericos para operar cálculos.\n",
    "\n",
    "Execute a célula de código abaixo para separar os dados dos estudantes em atributos e variáveis-alvo e verificar se algum desses atributos é não numérico."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Colunas de atributos:\n",
      "['school', 'sex', 'age', 'address', 'famsize', 'Pstatus', 'Medu', 'Fedu', 'Mjob', 'Fjob', 'reason', 'guardian', 'traveltime', 'studytime', 'failures', 'schoolsup', 'famsup', 'paid', 'activities', 'nursery', 'higher', 'internet', 'romantic', 'famrel', 'freetime', 'goout', 'Dalc', 'Walc', 'health', 'absences']\n",
      "\n",
      "Coluna-alvo: passed\n",
      "\n",
      "Feature values:\n",
      "  school sex  age address famsize Pstatus  Medu  Fedu     Mjob      Fjob  \\\n",
      "0     GP   F   18       U     GT3       A     4     4  at_home   teacher   \n",
      "1     GP   F   17       U     GT3       T     1     1  at_home     other   \n",
      "2     GP   F   15       U     LE3       T     1     1  at_home     other   \n",
      "3     GP   F   15       U     GT3       T     4     2   health  services   \n",
      "4     GP   F   16       U     GT3       T     3     3    other     other   \n",
      "\n",
      "    ...    higher internet  romantic  famrel  freetime goout Dalc Walc health  \\\n",
      "0   ...       yes       no        no       4         3     4    1    1      3   \n",
      "1   ...       yes      yes        no       5         3     3    1    1      3   \n",
      "2   ...       yes      yes        no       4         3     2    2    3      3   \n",
      "3   ...       yes      yes       yes       3         2     2    1    1      5   \n",
      "4   ...       yes       no        no       4         3     2    1    2      5   \n",
      "\n",
      "  absences  \n",
      "0        6  \n",
      "1        4  \n",
      "2       10  \n",
      "3        2  \n",
      "4        4  \n",
      "\n",
      "[5 rows x 30 columns]\n"
     ]
    }
   ],
   "source": [
    "# Extraia as colunas dos atributo\n",
    "feature_cols = list(student_data.columns[:-1])\n",
    "\n",
    "# Extraia a coluna-alvo 'passed'\n",
    "target_col = student_data.columns[-1] \n",
    "\n",
    "# Mostre a lista de colunas\n",
    "print \"Colunas de atributos:\\n{}\".format(feature_cols)\n",
    "print \"\\nColuna-alvo: {}\".format(target_col)\n",
    "\n",
    "# Separe os dados em atributos e variáveis-alvo (X_all e y_all, respectivamente)\n",
    "X_all = student_data[feature_cols]\n",
    "y_all = student_data[target_col]\n",
    "\n",
    "# Mostre os atributos imprimindo as cinco primeiras linhas\n",
    "print \"\\nFeature values:\"\n",
    "print X_all.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Pré-processar Colunas de Atributo\n",
    "\n",
    "Como você pode ver, há muitas colunas não numéricas que precisam ser convertidas! Muitas delas são simplesmente `yes`/`no`, por exemplo, a coluna `internet`. É razoável converter essas variáveis em valores (binários) `1`/`0`.\n",
    "\n",
    "Outras colunas, como `Mjob` e `Fjob`, têm mais do que dois valores e são conhecidas como variáveis categóricas. A maneira recomendada de lidar com esse tipo de coluna é criar uma quantidade de colunas proporcional aos possíveis valores (por exemplo, `Fjob_teacher`, `Fjob_other`, `Fjob_services`, etc), e assinalar `1` para um deles e `0` para todos os outros.\n",
    "\n",
    "Essas colunas geradas são por vezes chamadas de _variáveis postiças_ (_dummy variables_), e nós iremos utilizar a função [`pandas.get_dummies()`](http://pandas.pydata.org/pandas-docs/stable/generated/pandas.get_dummies.html?highlight=get_dummies#pandas.get_dummies) para fazer essa conversão. Execute a célula de código abaixo para executar a rotina de pré-processamento discutida nesta seção."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processed feature columns (48 total features):\n",
      "['school_GP', 'school_MS', 'sex_F', 'sex_M', 'age', 'address_R', 'address_U', 'famsize_GT3', 'famsize_LE3', 'Pstatus_A', 'Pstatus_T', 'Medu', 'Fedu', 'Mjob_at_home', 'Mjob_health', 'Mjob_other', 'Mjob_services', 'Mjob_teacher', 'Fjob_at_home', 'Fjob_health', 'Fjob_other', 'Fjob_services', 'Fjob_teacher', 'reason_course', 'reason_home', 'reason_other', 'reason_reputation', 'guardian_father', 'guardian_mother', 'guardian_other', 'traveltime', 'studytime', 'failures', 'schoolsup', 'famsup', 'paid', 'activities', 'nursery', 'higher', 'internet', 'romantic', 'famrel', 'freetime', 'goout', 'Dalc', 'Walc', 'health', 'absences']\n"
     ]
    }
   ],
   "source": [
    "def preprocess_features(X):\n",
    "    ''' Pré-processa os dados dos estudantes e converte as variáveis binárias não numéricas em\n",
    "        variáveis binárias (0/1). Converte variáveis categóricas em variáveis postiças. '''\n",
    "    \n",
    "    # Inicialize nova saída DataFrame\n",
    "    output = pd.DataFrame(index = X.index)\n",
    "\n",
    "    # Observe os dados em cada coluna de atributos \n",
    "    for col, col_data in X.iteritems():\n",
    "        \n",
    "        # Se o tipo de dado for não numérico, substitua todos os valores yes/no por 1/0\n",
    "        if col_data.dtype == object:\n",
    "            col_data = col_data.replace(['yes', 'no'], [1, 0])\n",
    "\n",
    "        # Se o tipo de dado for categórico, converta-o para uma variável dummy\n",
    "        if col_data.dtype == object:\n",
    "            # Example: 'school' => 'school_GP' and 'school_MS'\n",
    "            col_data = pd.get_dummies(col_data, prefix = col)  \n",
    "        \n",
    "        # Reúna as colunas revisadas\n",
    "        output = output.join(col_data)\n",
    "    \n",
    "    return output\n",
    "\n",
    "X_all = preprocess_features(X_all)\n",
    "print \"Processed feature columns ({} total features):\\n{}\".format(len(X_all.columns), list(X_all.columns))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Implementação: Divisão dos Dados de Treinamento e Teste\n",
    "Até agora, nós convertemos todos os atributos _categóricos_ em valores numéricos. Para o próximo passo, vamos dividir os dados (tanto atributos como os rótulos correspondentes) em conjuntos de treinamento e teste. Na célula de código abaixo, você irá precisar implementar o seguinte:\n",
    "- Embaralhe aleatoriamente os dados (`X_all`, `y_all`) em subconjuntos de treinamento e teste.\n",
    "  - Utilizar 300 pontos de treinamento (aproxidamente 75%) e 95 pontos de teste (aproximadamente 25%).\n",
    "  - Estabelecer um `random_state` para as funções que você utiliza, se a opção existir.\n",
    "  - Armazene os resultados em `X_train`, `X_test`, `y_train` e `y_test`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "O conjunto de treinamento tem 300 amostras.\n",
      "O conjunto de teste tem 95 amostras.\n"
     ]
    }
   ],
   "source": [
    "# TODO: Importe qualquer funcionalidade adicional de que você possa precisar aqui\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# TODO: Estabeleça o número de pontos de treinamento\n",
    "num_train = 300\n",
    "\n",
    "# Estabeleça o número de pontos de teste\n",
    "num_test = X_all.shape[0] - num_train\n",
    "\n",
    "# TODO: Emabaralhe e distribua o conjunto de dados de acordo com o número de pontos de treinamento e teste abaixo\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_all, y_all, test_size = num_test, random_state=42, stratify=y_all)\n",
    "\n",
    "# Mostre o resultado da distribuição\n",
    "print \"O conjunto de treinamento tem {} amostras.\".format(X_train.shape[0])\n",
    "print \"O conjunto de teste tem {} amostras.\".format(X_test.shape[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     school_GP  school_MS  sex_F  sex_M  age  address_R  address_U  \\\n",
      "273          1          0      0      1   17          1          0   \n",
      "265          1          0      0      1   18          1          0   \n",
      "64           1          0      1      0   15          0          1   \n",
      "131          1          0      1      0   15          0          1   \n",
      "122          1          0      1      0   16          0          1   \n",
      "\n",
      "     famsize_GT3  famsize_LE3  Pstatus_A    ...     higher  internet  \\\n",
      "273            1            0          0    ...          1         0   \n",
      "265            0            1          1    ...          1         1   \n",
      "64             0            1          0    ...          1         1   \n",
      "131            1            0          0    ...          1         1   \n",
      "122            0            1          0    ...          1         1   \n",
      "\n",
      "     romantic  famrel  freetime  goout  Dalc  Walc  health  absences  \n",
      "273         1       3         5      2     2     2       1         2  \n",
      "265         0       4         2      5     3     4       1        13  \n",
      "64          1       4         4      4     2     4       2         0  \n",
      "131         1       4         3      3     1     2       4         0  \n",
      "122         1       4         2      2     1     2       5         2  \n",
      "\n",
      "[5 rows x 48 columns] 273    yes\n",
      "265    yes\n",
      "64     yes\n",
      "131     no\n",
      "122    yes\n",
      "Name: passed, dtype: object\n"
     ]
    }
   ],
   "source": [
    "print X_train.head(), y_train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "273    yes\n",
      "265    yes\n",
      "64     yes\n",
      "Name: passed, dtype: object\n"
     ]
    }
   ],
   "source": [
    "print y_train[:3]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Treinando e Avaliando Modelos\n",
    "Nesta seção, você irá escolher 3 modelos de aprendizagem supervisionada que sejam apropriados para esse problema e que estejam disponíveis no `scikit-learn`. Primeiro você irá discutir o raciocínio por trás da escolha desses três modelos considerando suas vantagens e desvantagens e o que você sabe sobre os dados. Depois você irá ajustar o modelo a diferentes tamanhos de conjuntos de treinamento (com 100, 200 e 300 pontos) e medir a pontuação F<sub>1</sub>. Você vai precisar preencher três tabelas (uma para cada modelo) que mostrem o tamanho do conjunto de treinamento, o tempo de treinamento, o tempo de previsão e a pontuação F<sub>1</sub> no conjunto de treinamento.\n",
    "\n",
    "**Os seguintes modelos de aprendizagem supervisionada estão atualmente disponíveis no **[`scikit-learn`](http://scikit-learn.org/stable/supervised_learning.html)** para você escolher:**\n",
    "- Gaussian Naive Bayes (GaussianNB)\n",
    "- Árvores de Decisão\n",
    "- Métodos de agregação (Bagging, AdaBoost, Random Forest, Gradient Boosting)\n",
    "- K-Nearest Neighbors (KNeighbors)\n",
    "- Método do gradiente estocástico (SGDC)\n",
    "- Máquinas de vetores de suporte (SVM)\n",
    "- Regressão logística"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Questão 2 - Aplicação dos Modelos\n",
    "*Liste três modelos de aprendizagem supervisionada que são apropriadas para esse problema. Para cada modelo escolhido:*\n",
    "- Descreva uma aplicação em mundo real na indústria em que o modelo pode ser aplicado. *(Talvez você precise fazer um pouco de pesquisa para responder essa questão – dê as devidas referências!)* \n",
    "- Quais são as vantagens do modelo; quando ele tem desempenho melhor? \n",
    "- Quais são as desvantagens do modelo, quando ele tem desempenho pior?\n",
    "- O que faz desse modelo um bom candidato para o problema, considerando o que você sabe sobre os dados?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Resposta: **\n",
    "\n",
    "### **Modelo 1: Gaussian Naive Bayes**\n",
    "\n",
    "1. **Aplicação**: detecção de spam em emails, cassificação de documentos, predição de palavras em um texto.\n",
    "\n",
    "  * Referências: [Quora](https://www.quora.com/In-what-real-world-applications-is-Naive-Bayes-classifier-used)\n",
    "  \n",
    "2. **Vantagens:** Simples e facil de implementar; mesmo que as premissas de independencia não sejam verdadeiras, na prática o modelo se sai bem; não precisa de muitos dados de treinamento; não é sensível a variáveis irrelevantes.\n",
    "\n",
    "  * Referências: [Quora](https://www.quora.com/What-are-the-advantages-of-using-a-naive-Bayes-for-classification) [Echen](http://blog.echen.me/2011/04/27/choosing-a-machine-learning-classifier/)\n",
    "  \n",
    "3. **Desvantagens: **Assume que as variáveis são independentes, o que pode não ser verdade nesse caso. Por exemplo, a variável _Absences_ pode depender da variável _Health_, uma vez que pessoas menos saudaveis podem ficar mais doentes e talvez faltar mais, ou a variável _Goout_ pode estar correlacionada com a _Freetime_, visto que quem tem mais tempo livre tende a sair mais.\n",
    "\n",
    "  * Referências: [Quora](https://www.quora.com/What-are-the-disadvantages-of-using-a-naive-bayes-for-classification)\n",
    "  \n",
    "4. **Escolha:**: modelo de simples estruturação, que utiliza probabilidades e que apresenta bons resultados práticos\n",
    " \n",
    "\n",
    "\n",
    "### **Modelo 2: SVM**  \n",
    "\n",
    "1. **Aplicação**: Classificação de imagens, detecção de rostos, reconhecimento de letras escritas a mão.\n",
    "\n",
    "  * Referências:[data-flair](https://data-flair.training/blogs/applications-of-svm/)\n",
    "  \n",
    "2. **Vantagens:** Método bom para fronteiras de decisão não-lineares; robusto contra _overfitting_, apresentando boa generalização, por possuir um parametro regularizador; treino relativamente fácil.\n",
    "\n",
    "  * Referências: [Echen](http://blog.echen.me/2011/04/27/choosing-a-machine-learning-classifier/),  [EliteDataScience](https://elitedatascience.com/machine-learning-algorithms#classification), [PDF](http://www.ijastnet.com/journals/Vol_7_No_2_June_2017/2.pdf), [Stack Exchange](https://stats.stackexchange.com/questions/24437/advantages-and-disadvantages-of-svm)\n",
    "  \n",
    "3. **Desvantagens: ** Dificuldade de interpretação em alguns casos, devido ao fato de ser um modelo não-paramétrico; É dependente de um bom kernel para fazer a separação. \n",
    "\n",
    "  * Referências:  [PDF](http://www.ijastnet.com/journals/Vol_7_No_2_June_2017/2.pdf), [Stack Exchange](https://stats.stackexchange.com/questions/24437/advantages-and-disadvantages-of-svm)\n",
    "  \n",
    "4. **Escolha:**: è um método muito popular atualmente, bastante utilizado e que apresenta ótimos resultados em problemas de classificação.\n",
    "\n",
    "  \n",
    "  \n",
    "\n",
    "### **Modelo 3: Regressão logística** \n",
    "\n",
    "1. **Aplicação**: é aplicado em problemas de classificação binária, predições - a regressão logística permite obter a probabilidade de resultados, ajudando na tomada de decisão.\n",
    "  * Referências: [UBC](https://www.stat.ubc.ca/~rollin/teach/536a/confEtc.html#(2))\n",
    "  \n",
    "2. **Vantagens:** O modelo não é sensível à correlação entre variáveis (como o Naive Bayes); ele oferece uma interpretação  probabilística e é bom para problemas de classificação.\n",
    "\n",
    "  * Referências: [Echen](http://blog.echen.me/2011/04/27/choosing-a-machine-learning-classifier/)\n",
    "  \n",
    "3. **Desvantagens: **  A regressão logística tende a não performar muito bem em fronteiras de decisão não-lineares e não são flexíveis o suficiente para entender relações complexas, além disso, é recomendável que as duas classificações possíveis estejam presentes em números iguais.\n",
    "\n",
    "  * Referências: [EliteDataScience](https://elitedatascience.com/machine-learning-algorithms#classification)\n",
    "  \n",
    "4. **Escolha:**: É um modelo muito utilizado, bom para classificações binária, como esse problema (passou ou não passou) e baixo tempo de treinamento.\n",
    "\n",
    "  \n",
    "  \n",
    "\n",
    "### [EXTRA] **Modelo 4: Árvores de decisão** \n",
    "\n",
    "1. **Aplicação**: Arvores de decisão são utilizadas na classificação de estrelas, filtração de ruídos de imagens, controle de sistemas não-lineares, diagnósticos médicos, entre outros.\n",
    "\n",
    "  * Referências: [cbcb](http://www.cbcb.umd.edu/~salzberg/docs/murthy_thesis/survey/node32.html)\n",
    "  \n",
    "2. **Vantagens:** Fáceis de interpretar e explicar; São muito utilizados para problemas de classificação pois apresentam bons resultados, superando muitas vezes os outros métodos; Não necessitam de muito poder computacional; Não possuem muitos parâmetros.\n",
    "\n",
    "  * Referências: [Echen](http://blog.echen.me/2011/04/27/choosing-a-machine-learning-classifier/)\n",
    "  \n",
    "3. **Desvantagens: ** Tem tendências de apresentar _overfitting_; Não suportam online learning (o que não é o caso nesse projeto);\n",
    "\n",
    "  * Referências: [EliteDataScience](https://elitedatascience.com/machine-learning-algorithms#classification)\n",
    "  \n",
    "4. **Escolha:**: Esse modelo foi um dos escolhidos por possuir várias aplicações e produzir bons resultados em problemas de classificação.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Configuração\n",
    "Execute a célula de código abaixo para inicializar três funções de ajuda que você pode utilizar para treinar e testar os três modelos de aprendizagem supervisionada que você escolheu acima. As funções são as seguintes:\n",
    "- `train_classifier` - recebe como parâmetro um classificador e dados de treinamento e ajusta o classificador aos dados.\n",
    "- `predict_labels` - recebe como parâmetro um classificador ajustado, atributos e rótulo alvo e faz estimativas utilizando a pontuação do F<sub>1</sub>.\n",
    "- `train_predict` - recebe como entrada um classificador, e dados de treinamento e teste, e executa `train_clasifier` e `predict_labels`.\n",
    " - Essa função vai dar a pontuação F<sub>1</sub> tanto para os dados de treinamento como para os de teste, separadamente."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_classifier(clf, X_train, y_train):\n",
    "    ''' Ajusta um classificador para os dados de treinamento. '''\n",
    "    \n",
    "    # Inicia o relógio, treina o classificador e, então, para o relógio\n",
    "    start = time()\n",
    "    clf.fit(X_train, y_train)\n",
    "    end = time()\n",
    "    \n",
    "    # Imprime os resultados\n",
    "    print \"O modelo foi treinado em {:.4f} segundos\".format(end - start)\n",
    "\n",
    "    \n",
    "def predict_labels(clf, features, target):\n",
    "    ''' Faz uma estimativa utilizando um classificador ajustado baseado na pontuação F1. '''\n",
    "    \n",
    "    # Inicia o relógio, faz estimativas e, então, o relógio para\n",
    "    start = time()\n",
    "    y_pred = clf.predict(features)\n",
    "    end = time()\n",
    "    \n",
    "    # Imprime os resultados de retorno\n",
    "    print \"As previsões foram feitas em {:.4f} segundos.\".format(end - start)\n",
    "    return f1_score(target.values, y_pred, pos_label='yes')\n",
    "\n",
    "\n",
    "def train_predict(clf, X_train, y_train, X_test, y_test):\n",
    "    ''' Treina e faz estimativas utilizando um classificador baseado na pontuação do F1. '''\n",
    "    \n",
    "    # Indica o tamanho do classificador e do conjunto de treinamento\n",
    "    print \"Treinando um {} com {} pontos de treinamento. . .\".format(clf.__class__.__name__, len(X_train))\n",
    "    \n",
    "    # Treina o classificador\n",
    "    train_classifier(clf, X_train, y_train)\n",
    "    \n",
    "    # Imprime os resultados das estimativas de ambos treinamento e teste\n",
    "    print \"Pontuação F1 para o conjunto de treino: {:.4f}.\".format(predict_labels(clf, X_train, y_train))\n",
    "    print \"Pontuação F1 para o conjunto de teste: {:.4f}.\".format(predict_labels(clf, X_test, y_test))\n",
    "    return predict_labels(clf, X_test, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Implementação: Métricas de Desempenho do Modelo\n",
    "Com as funções acima, você vai importar os três modelos de aprendizagem supervisionada de sua escolha e executar a função `train_prediction` para cada um deles. Lembre-se de que você vai precisar treinar e usar cada classificador para três diferentes tamanhos de conjuntos de treinamentos: 100, 200 e 300 pontos. Então você deve ter 9 saídas diferentes abaixo – 3 para cada modelo utilizando cada tamanho de conjunto de treinamento. Na célula de código a seguir, você deve implementar o seguinte:\n",
    "- Importe os três modelos de aprendizagem supervisionada que você escolheu na seção anterior.\n",
    "- Inicialize os três modelos e armazene eles em `clf_A`, `clf_B` e `clf_C`.\n",
    " - Defina um `random_state` para cada modelo, se a opção existir.\n",
    " - **Nota:** Utilize as configurações padrão para cada modelo – você vai calibrar um modelo específico em uma seção posterior.\n",
    "- Crie diferentes tamanhos de conjuntos de treinamento para treinar cada modelo.\n",
    " - *Não embaralhe e distribua novamente os dados! Os novos pontos de treinamento devem ser tirados de `X_train` e `y_train`.*\n",
    "- Treine cada modelo com cada tamanho de conjunto de treinamento e faça estimativas com o conjunto de teste (9 vezes no total).  \n",
    "**Nota:** Três tabelas são fornecidas depois da célula de código a seguir, nas quais você deve anotar seus resultados."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Importe os três modelos de aprendizagem supervisionada do sklearn\n",
    "from sklearn.naive_bayes import GaussianNB             #Naive Bayes\n",
    "from sklearn.svm import SVC                            #SVM\n",
    "from sklearn.linear_model import LogisticRegression    #Regrassão Logística\n",
    "from sklearn import tree                               #Arvore de decisão\n",
    "\n",
    "# TODO: Inicialize os três modelos\n",
    "clf_A = GaussianNB()\n",
    "clf_B = SVC(random_state = 21)\n",
    "clf_C = LogisticRegression(random_state = 41)\n",
    "clf_D = tree.DecisionTreeClassifier(random_state = 21)\n",
    "\n",
    "Modelos = [clf_A, clf_B, clf_C, clf_D]\n",
    "\n",
    "# TODO: Configure os tamanho dos conjuntos de treinamento\n",
    "X_train_100 = X_train[:100]\n",
    "y_train_100 = y_train[:100]\n",
    "\n",
    "X_train_200 = X_train[:200]\n",
    "y_train_200 = y_train[:200]\n",
    "\n",
    "X_train_300 = X_train[:300]\n",
    "y_train_300 = y_train[:300]\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Treinando um GaussianNB com 100 pontos de treinamento. . .\n",
      "O modelo foi treinado em 0.0040 segundos\n",
      "As previsões foram feitas em 0.0000 segundos.\n",
      "Pontuação F1 para o conjunto de treino: 0.7752.\n",
      "As previsões foram feitas em 0.0040 segundos.\n",
      "Pontuação F1 para o conjunto de teste: 0.6457.\n",
      "As previsões foram feitas em 0.0000 segundos.\n",
      " \n",
      "Treinando um GaussianNB com 200 pontos de treinamento. . .\n",
      "O modelo foi treinado em 0.0040 segundos\n",
      "As previsões foram feitas em 0.0000 segundos.\n",
      "Pontuação F1 para o conjunto de treino: 0.8060.\n",
      "As previsões foram feitas em 0.0040 segundos.\n",
      "Pontuação F1 para o conjunto de teste: 0.7218.\n",
      "As previsões foram feitas em 0.0000 segundos.\n",
      " \n",
      "Treinando um GaussianNB com 300 pontos de treinamento. . .\n",
      "O modelo foi treinado em 0.0040 segundos\n",
      "As previsões foram feitas em 0.0000 segundos.\n",
      "Pontuação F1 para o conjunto de treino: 0.8134.\n",
      "As previsões foram feitas em 0.0000 segundos.\n",
      "Pontuação F1 para o conjunto de teste: 0.7761.\n",
      "As previsões foram feitas em 0.0000 segundos.\n",
      " \n",
      "-------------------------------------------------\n",
      "Treinando um SVC com 100 pontos de treinamento. . .\n",
      "O modelo foi treinado em 0.0000 segundos\n",
      "As previsões foram feitas em 0.0000 segundos.\n",
      "Pontuação F1 para o conjunto de treino: 0.8354.\n",
      "As previsões foram feitas em 0.0000 segundos.\n",
      "Pontuação F1 para o conjunto de teste: 0.8025.\n",
      "As previsões foram feitas em 0.0040 segundos.\n",
      " \n",
      "Treinando um SVC com 200 pontos de treinamento. . .\n",
      "O modelo foi treinado em 0.0040 segundos\n",
      "As previsões foram feitas em 0.0040 segundos.\n",
      "Pontuação F1 para o conjunto de treino: 0.8431.\n",
      "As previsões foram feitas em 0.0040 segundos.\n",
      "Pontuação F1 para o conjunto de teste: 0.8105.\n",
      "As previsões foram feitas em 0.0040 segundos.\n",
      " \n",
      "Treinando um SVC com 300 pontos de treinamento. . .\n",
      "O modelo foi treinado em 0.0080 segundos\n",
      "As previsões foram feitas em 0.0080 segundos.\n",
      "Pontuação F1 para o conjunto de treino: 0.8664.\n",
      "As previsões foram feitas em 0.0040 segundos.\n",
      "Pontuação F1 para o conjunto de teste: 0.8052.\n",
      "As previsões foram feitas em 0.0000 segundos.\n",
      " \n",
      "-------------------------------------------------\n",
      "Treinando um LogisticRegression com 100 pontos de treinamento. . .\n",
      "O modelo foi treinado em 0.0000 segundos\n",
      "As previsões foram feitas em 0.0040 segundos.\n",
      "Pontuação F1 para o conjunto de treino: 0.8671.\n",
      "As previsões foram feitas em 0.0000 segundos.\n",
      "Pontuação F1 para o conjunto de teste: 0.7068.\n",
      "As previsões foram feitas em 0.0000 segundos.\n",
      " \n",
      "Treinando um LogisticRegression com 200 pontos de treinamento. . .\n",
      "O modelo foi treinado em 0.0040 segundos\n",
      "As previsões foram feitas em 0.0000 segundos.\n",
      "Pontuação F1 para o conjunto de treino: 0.8211.\n",
      "As previsões foram feitas em 0.0000 segundos.\n",
      "Pontuação F1 para o conjunto de teste: 0.7391.\n",
      "As previsões foram feitas em 0.0000 segundos.\n",
      " \n",
      "Treinando um LogisticRegression com 300 pontos de treinamento. . .\n",
      "O modelo foi treinado em 0.0040 segundos\n",
      "As previsões foram feitas em 0.0000 segundos.\n",
      "Pontuação F1 para o conjunto de treino: 0.8512.\n",
      "As previsões foram feitas em 0.0000 segundos.\n",
      "Pontuação F1 para o conjunto de teste: 0.7500.\n",
      "As previsões foram feitas em 0.0000 segundos.\n",
      " \n",
      "-------------------------------------------------\n",
      "Treinando um DecisionTreeClassifier com 100 pontos de treinamento. . .\n",
      "O modelo foi treinado em 0.0000 segundos\n",
      "As previsões foram feitas em 0.0000 segundos.\n",
      "Pontuação F1 para o conjunto de treino: 1.0000.\n",
      "As previsões foram feitas em 0.0000 segundos.\n",
      "Pontuação F1 para o conjunto de teste: 0.6721.\n",
      "As previsões foram feitas em 0.0000 segundos.\n",
      " \n",
      "Treinando um DecisionTreeClassifier com 200 pontos de treinamento. . .\n",
      "O modelo foi treinado em 0.0160 segundos\n",
      "As previsões foram feitas em 0.0000 segundos.\n",
      "Pontuação F1 para o conjunto de treino: 1.0000.\n",
      "As previsões foram feitas em 0.0000 segundos.\n",
      "Pontuação F1 para o conjunto de teste: 0.7097.\n",
      "As previsões foram feitas em 0.0000 segundos.\n",
      " \n",
      "Treinando um DecisionTreeClassifier com 300 pontos de treinamento. . .\n",
      "O modelo foi treinado em 0.0000 segundos\n",
      "As previsões foram feitas em 0.0000 segundos.\n",
      "Pontuação F1 para o conjunto de treino: 1.0000.\n",
      "As previsões foram feitas em 0.0000 segundos.\n",
      "Pontuação F1 para o conjunto de teste: 0.7000.\n",
      "As previsões foram feitas em 0.0000 segundos.\n",
      " \n",
      "-------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "# TODO: Executar a função 'train_predict' para cada classificador e cada tamanho de conjunto de treinamento\n",
    "# train_predict(clf, X_train, y_train, X_test, y_test)\n",
    "\n",
    "xt = []\n",
    "yt = []\n",
    "zt = []\n",
    "\n",
    "for modelo in Modelos:\n",
    "    x = train_predict(modelo, X_train_100, y_train_100, X_test, y_test)\n",
    "    xt.append(x)\n",
    "    print \" \"\n",
    "    \n",
    "    y = train_predict(modelo, X_train_200, y_train_200, X_test, y_test)\n",
    "    yt.append(y)\n",
    "    print \" \"\n",
    "    \n",
    "    z = train_predict(modelo, X_train_300, y_train_300, X_test, y_test)\n",
    "    zt.append(z)\n",
    "    print \" \"\n",
    "    \n",
    "    print \"-------------------------------------------------\"\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.64566929133858275, 0.80254777070063688, 0.70676691729323315, 0.67213114754098358]\n",
      "[0.72180451127819545, 0.8104575163398694, 0.73913043478260876, 0.70967741935483863]\n",
      "[0.77611940298507476, 0.80519480519480513, 0.74999999999999989, 0.69999999999999996]\n"
     ]
    }
   ],
   "source": [
    "print xt\n",
    "print yt\n",
    "print zt\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classificador 1 - Gaussian Naive Bayes\n",
      "100 pontos de treinamento - Pontuação F1 do teste :  0.645669291339\n",
      "200 pontos de treinamento - Pontuação F1 do teste :  0.721804511278\n",
      "300 pontos de treinamento - Pontuação F1 do teste :  0.776119402985\n",
      "  \n",
      "Classificador 2 - SVM\n",
      "100 pontos de treinamento - Pontuação F1 do teste :  0.802547770701\n",
      "200 pontos de treinamento - Pontuação F1 do teste :  0.81045751634\n",
      "300 pontos de treinamento - Pontuação F1 do teste :  0.805194805195\n",
      "  \n",
      "Classificador 3 - Logistic Regression\n",
      "100 pontos de treinamento - Pontuação F1 do teste :  0.706766917293\n",
      "200 pontos de treinamento - Pontuação F1 do teste :  0.739130434783\n",
      "300 pontos de treinamento - Pontuação F1 do teste :  0.75\n",
      "  \n",
      "Classificador 4 - Decision Trees\n",
      "100 pontos de treinamento - Pontuação F1 do teste :  0.672131147541\n",
      "200 pontos de treinamento - Pontuação F1 do teste :  0.709677419355\n",
      "300 pontos de treinamento - Pontuação F1 do teste :  0.7\n"
     ]
    }
   ],
   "source": [
    "print 'Classificador 1 - Gaussian Naive Bayes'\n",
    "print '100 pontos de treinamento - Pontuação F1 do teste : ', xt[0]\n",
    "print '200 pontos de treinamento - Pontuação F1 do teste : ', yt[0]\n",
    "print '300 pontos de treinamento - Pontuação F1 do teste : ', zt[0]\n",
    "print '  '\n",
    "\n",
    "print 'Classificador 2 - SVM'\n",
    "print '100 pontos de treinamento - Pontuação F1 do teste : ', xt[1]\n",
    "print '200 pontos de treinamento - Pontuação F1 do teste : ', yt[1]\n",
    "print '300 pontos de treinamento - Pontuação F1 do teste : ', zt[1]\n",
    "print '  '\n",
    "\n",
    "print 'Classificador 3 - Logistic Regression'\n",
    "print '100 pontos de treinamento - Pontuação F1 do teste : ', xt[2]\n",
    "print '200 pontos de treinamento - Pontuação F1 do teste : ', yt[2]\n",
    "print '300 pontos de treinamento - Pontuação F1 do teste : ', zt[2]\n",
    "print '  '\n",
    "\n",
    "print 'Classificador 4 - Decision Trees'\n",
    "print '100 pontos de treinamento - Pontuação F1 do teste : ', xt[3]\n",
    "print '200 pontos de treinamento - Pontuação F1 do teste : ', yt[3]\n",
    "print '300 pontos de treinamento - Pontuação F1 do teste : ', zt[3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.64566929133858275, 0.80254777070063688, 0.70676691729323315, 0.67213114754098358] [0.72180451127819545, 0.8104575163398694, 0.73913043478260876, 0.70967741935483863] [0.77611940298507476, 0.80519480519480513, 0.74999999999999989, 0.69999999999999996]\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAA4kAAAG5CAYAAAAjy3HRAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nHcqdjPfTjQ8AAAAASUVORK5CYII=\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0xf099c18>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "df = pd.read_csv(\"matriz_resultados_csv.csv\")\n",
    "df = df[['Tamanho','Modelo', 'F1_teste']].copy()\n",
    "\n",
    "bar1 = xt\n",
    "bar2 = yt\n",
    "bar3 = zt\n",
    "\n",
    "#for i in range(len(df['F1_teste']+1)):\n",
    "    #if df.loc[i]['Tamanho'] == 100:\n",
    "       # bar1.append(df.loc[i]['F1_teste'])\n",
    "    #elif df.loc[i]['Tamanho'] == 200:\n",
    "        #bar2.append(df.loc[i]['F1_teste'])\n",
    "    #elif df.loc[i]['Tamanho'] == 300:\n",
    "        #bar3.append(df.loc[i]['F1_teste'])   \n",
    "\n",
    "print bar1, bar2 ,bar3\n",
    "\n",
    "barWidth = 0.25      \n",
    "        \n",
    "# Setting the positions and width for the bars\n",
    "r1 = np.arange(len(bar1))\n",
    "r2 = [x + barWidth for x in r1]\n",
    "r3 = [x + barWidth for x in r2]\n",
    "width = 0.25 \n",
    "    \n",
    "# Plotting the bars\n",
    "fig, ax = plt.subplots(figsize=(15,7))\n",
    "plt.style.use('seaborn-darkgrid')\n",
    "\n",
    "# Create a bar with pre_score data,\n",
    "# in position pos,\n",
    "plt.bar(r1, \n",
    "        #using df['pre_score'] data,\n",
    "        bar1, \n",
    "        # of width\n",
    "        width, \n",
    "        # with alpha 0.5\n",
    "        alpha=0.7, \n",
    "        # with color\n",
    "        #color='#EE3224',\n",
    "        color = 'xkcd:aqua' ,\n",
    "        # with label the first value in first_name\n",
    "        label= '100') \n",
    "\n",
    "# Create a bar with mid_score data,\n",
    "# in position pos + some width buffer,\n",
    "plt.bar(r2, \n",
    "        #using df['mid_score'] data,\n",
    "        bar2,\n",
    "        # of width\n",
    "        width, \n",
    "        # with alpha 0.5\n",
    "        alpha=0.7, \n",
    "        # with color\n",
    "        #color='#F78F1E',\n",
    "        color = 'xkcd:turquoise' ,\n",
    "        # with label the second value in first_name\n",
    "        label= '200') \n",
    "\n",
    "# Create a bar with post_score data,\n",
    "# in position pos + some width buffer,\n",
    "plt.bar(r3, \n",
    "        #using df['post_score'] data,\n",
    "        bar3, \n",
    "        # of width\n",
    "        width, \n",
    "        # with alpha\n",
    "        alpha=0.7, \n",
    "        # with color\n",
    "        #color='#FFC222'\n",
    "        color = 'xkcd:teal', \n",
    "        # with label the third value in first_name\n",
    "        label='300') \n",
    "\n",
    "plt.axhline(y=np.mean(bar1 +bar2+ bar3), alpha = 0.7, color='dimgray')\n",
    "\n",
    "# Set the y axis label\n",
    "ax.set_ylabel('F1 Score', fontsize = 20)\n",
    "\n",
    "# Set the chart's title\n",
    "ax.set_title('F1 Scores', fontsize = 25)\n",
    "\n",
    "# Set the position of the x ticks\n",
    "ax.set_xticks([p + 1.5 * width for p in r1])\n",
    "\n",
    "# Set the labels for the x ticks\n",
    "ax.set_xticklabels(['Naive Bayes', 'SVM', 'Linear Regression', 'Decision Trees'], fontsize = 20)\n",
    "\n",
    "# Set the grids\n",
    "#ax.grid(linestyle='-', linewidth=2)\n",
    "\n",
    "# Setting the x-axis and y-axis limits\n",
    "plt.xlim(min(r1)-width, max(r1)+width*4)\n",
    "plt.ylim(0,1)\n",
    "plt.tick_params(labelsize=20)\n",
    "\n",
    "# Adding the legend and showing the plot\n",
    "plt.legend(['media','100', '200', '300'], loc='upper right', fontsize = 20, ncol=44)\n",
    "\n",
    "plt.show()\n",
    "\n",
    "#https://chrisalbon.com/python/data_visualization/matplotlib_grouped_bar_plot/\n",
    "#"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.07359307359\n",
      "1.03746253746\n"
     ]
    }
   ],
   "source": [
    "print zt[1]/zt[2]\n",
    "print zt[1]/zt[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Escolhendo o Melhor Modelo\n",
    "Nesta seção final, você irá escolher dos três modelos de aprendizagem supervisionada o *melhor* para utilizar os dados dos estudantes. Você então executará um busca em matriz otimizada para o modelo em todo o conjunto de treinamento (`X_train` e `y_train`) ao calibrar pelo menos um parâmetro, melhorando em comparação a pontuação F<sub>1</sub> do modelo não calibrado. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Questão 3 - Escolhendo o Melhor Modelo\n",
    "*Baseando-se nos experimentos que você executou até agora, explique em um ou dois parágrafos ao conselho de supervisores qual modelo que você escolheu como o melhor. Qual modelo é o mais apropriado baseado nos dados disponíveis, recursos limitados, custo e desempenho?*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Resposta: ** \n",
    "\n",
    "O melhor modelo encontrado foi o **Naive Bayes**: Apesar de não ter obtido a maior pontuação F1, o método de Naive Bayes se mostrou rápido no processamento e indicou que um possível aumento no número de dados de treinamento resulte em uma pontuação cada vez maior, visto a progressão do valor da pontuação (ver gráfico acima). Além do baixo tempo de processamento, o método de Naive Bayes retorna para o usuário a probabilidade do evento acontecer, uma vantagem em relação ao método mais pontuado (SVM), que é não paramétrico e de difícil interpretação.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Questão 4 – O Modelo para um Leigo\n",
    "*Em um ou dois parágrafos, explique para o conselho de supervisores, utilizando termos leigos, como o modelo final escolhido deve trabalhar. Tenha certeza que você esteja descrevendo as melhores qualidades do modelo, por exemplo, como o modelo é treinado e como ele faz uma estimativa. Evite jargões técnicos ou matemáticos, como descrever equações ou discutir a implementação do algoritmo.*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " **Resposta: **  \n",
    " **[Naive Bayes]**: o método de Naive Bayes é um método de probabilidade condicional, ou seja, calcula a probabilidade do acontecimento de algo (nesse caso, a probabilidade de um aluno passar na matéria) dado que outra coisa ja aconteceu (as variáveis medidas de cada aluno). Para o cálculo do algoritmo, este pressupõe que as variáveis sejam idependentes, ou seja, uma não tem relação e nem influencia a outra (nesse caso, algumas variáveis são dependentes, como por exemplo o tempo livre e o número de vezes que a pessoa sai: quanto mais tempo livre, mais se espera que uma pessoa saia ou faça outra coisa). Na pratica, esse algoritmo se sai bem mesmo quando existe relação entre as variáveis. Depois de determinadas as probabilidades de acontecimento de cada atributo, a estimativa é feita por meio de relações do cálculo da regra de Bayes e o resultado final informa a probabilidade do acontecimento estudado (passar na matéria) acontecer.\n",
    " \n",
    "**[Antigo - Regressão Logística]**: Primeiramente, o modelo de regressão logística serve para classificações do tipo \"Sim\" e \"Não\", 0 ou 1, ou seja, serve para dizer se algo está em um grupo ou em outro. Como é possivel observar na imagem abaixo, os conjuntos de pontos estão distribuidos em duas linhas horizontais (só existem dois valores para o eixo _y_ do gráfico). Diferentemente da regressão linear, que busca ajustar uma linha aos pontos e, nesse caso falha, a regressão logistica tem uma curva do tipo \"_S_\" e se \"acomoda\" muito melhor aos dados, prevendo melhor qual sera a classificação dado o valor da variavel _x_. Também, como possui um valor entre 0 e 1, comporta-se como uma probabilidade, que tem seu valor obtido no eixo _y_ do gráfico.\n",
    " \n",
    "<img src=\"img/linear_logistic.jpg\" width=\"600\"/>\n",
    "\n",
    "O modelo é treinado buscando o melhor ajute da função logística aos pontos. Depois de treinado, ao se colocar valores novos dentro do modelo, ele terá como resposta um valor de probabilidade entre 0 e 1 (nesse caso, 1= passou e 0 = não passou), qualquer valor entre 0 e 1 mostra uma _incerteza_ quanto ao destino do aluno e representa a probabilidade dele _passar_ na matéria.\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Implementação: Calibrando o Modelo (_Tuning_)\n",
    "Calibre o modelo escolhido. Utilize busca em matriz (`GridSearchCV`) com, pelo menos, um parâmetro importante calibrado com, pelo menos, 3 valores diferentes. Você vai precisar utilizar todo o conjunto de treinamento para isso. Na célula de código abaixo, você deve implementar o seguinte:\n",
    "- Importe [`sklearn.grid_search.gridSearchCV`](http://scikit-learn.org/stable/modules/generated/sklearn.grid_search.GridSearchCV.html) e [`sklearn.metrics.make_scorer`](http://scikit-learn.org/stable/modules/generated/sklearn.metrics.make_scorer.html).\n",
    "- Crie o dicionário de parâmetros que você deseja calibrar para o modelo escolhido.\n",
    " - Examplo: `parameters = {'parameter' : [list of values]}`.\n",
    "- Inicialize o classificador que você escolheu e armazene-o em `clf`.\n",
    "- Crie a função de pontuação F<sub>1</sub> utilizando `make_scorer` e armazene-o em `f1_scorer`.\n",
    " - Estabeleça o parâmetro `pos_label` para o valor correto!\n",
    "- Execute uma busca em matriz no classificador `clf` utilizando o `f1_scorer` como método de pontuação e armazene-o em `grid_obj`.\n",
    "- Treine o objeto de busca em matriz com os dados de treinamento (`X_train`, `y_train`) e armazene-o em `grid_obj`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "As previsões foram feitas em 0.0000 segundos.\n",
      "O modelo calibrado tem F1 de 0.8365 no conjunto de treinamento.\n",
      "As previsões foram feitas em 0.0000 segundos.\n",
      "O modelo calibrado tem F1 de 0.8079 no conjunto de teste.\n",
      "LogisticRegression(C=100, class_weight=None, dual=False, fit_intercept=True,\n",
      "          intercept_scaling=1, max_iter=50, multi_class='ovr', n_jobs=1,\n",
      "          penalty='l2', random_state=21, solver='newton-cg', tol=0.0001,\n",
      "          verbose=0, warm_start=False)\n",
      " \n",
      "Treinando um LogisticRegression com 300 pontos de treinamento. . .\n",
      "O modelo foi treinado em 0.0000 segundos\n",
      "As previsões foram feitas em 0.0000 segundos.\n",
      "Pontuação F1 para o conjunto de treino: 0.8024.\n",
      "As previsões foram feitas em 0.0000 segundos.\n",
      "Pontuação F1 para o conjunto de teste: 0.8050.\n",
      "As previsões foram feitas em 0.0000 segundos.\n",
      "LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,\n",
      "          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,\n",
      "          penalty='l2', random_state=21, solver='liblinear', tol=0.0001,\n",
      "          verbose=0, warm_start=False)\n"
     ]
    }
   ],
   "source": [
    "# TODO: Importe 'GridSearchCV' e 'make_scorer'\n",
    "from sklearn.metrics import make_scorer \n",
    "from sklearn.grid_search import  GridSearchCV\n",
    "from sklearn import preprocessing\n",
    "from sklearn.cross_validation import StratifiedShuffleSplit\n",
    "\n",
    "# TODO: Crie a lista de parâmetros que você gostaria de calibrar\n",
    "parameters = {'solver':('newton-cg', 'lbfgs', 'liblinear', 'saga'), \n",
    "              'C':[ 0.01, 0.1, 1.0, 10, 100], \n",
    "              'max_iter':[50, 100, 400, 700]}\n",
    "\n",
    "# TODO: Inicialize o classificador\n",
    "#clf = SVC(random_state = 41)\n",
    "clf = LogisticRegression()\n",
    "\n",
    "X_train_n = preprocessing.normalize(X_train, norm='l1')\n",
    "X_test_n = preprocessing.normalize(X_test, norm='l1')\n",
    "\n",
    "\n",
    "# TODO: Faça uma função de pontuação f1 utilizando 'make_scorer' \n",
    "f1_scorer = make_scorer(f1_score, pos_label='yes')\n",
    "\n",
    "\n",
    "# TODO: Execute uma busca em matriz no classificador utilizando o f1_scorer como método de pontuação\n",
    "grid_obj = GridSearchCV(estimator = clf, \n",
    "                        param_grid = parameters, \n",
    "                        scoring = f1_scorer,\n",
    "                        cv = StratifiedShuffleSplit(y_train,n_iter = 50,random_state = 42))\n",
    "\n",
    "# TODO: Ajuste o objeto de busca em matriz para o treinamento de dados e encontre os parâmetros ótimos\n",
    "grid_obj = grid_obj.fit(X_train_n, y_train)\n",
    "\n",
    "# Get the estimator\n",
    "clf = grid_obj.best_estimator_\n",
    "\n",
    "# Reporte a pontuação final F1 para treinamento e teste depois de calibrar os parâmetrosprint \"Tuned model has a training F1 score of {:.4f}.\".format(predict_labels(clf, X_train, y_train))\n",
    "print \"O modelo calibrado tem F1 de {:.4f} no conjunto de treinamento.\".format(predict_labels(clf, X_train_n, y_train))\n",
    "print \"O modelo calibrado tem F1 de {:.4f} no conjunto de teste.\".format(predict_labels(clf, X_test_n, y_test))\n",
    "print clf\n",
    "\n",
    "print \" \"\n",
    "\n",
    "l_r = LogisticRegression( random_state = 21 )\n",
    "train_predict( l_r, X_train_n, y_train, X_test_n, y_test)\n",
    "print l_r\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2 2\n"
     ]
    }
   ],
   "source": [
    "from collections import Counter\n",
    "y_test.describe()\n",
    "\n",
    "x = Counter(y_test)\n",
    "y = Counter(y_train)\n",
    "\n",
    "\n",
    "print x['yes']/x['no'] , y['yes']/y['no']\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Text(0.5,28.5,u'Predicted')"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAZAAAAFFCAYAAADCTLtQAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0xf936320>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import seaborn as sns # Install using 'pip install seaborn'\n",
    "from sklearn.metrics import confusion_matrix\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "cm_test = confusion_matrix(y_test, clf.predict(X_test))\n",
    "\n",
    "plt.figure(figsize=(7,5))\n",
    "sns.heatmap(cm_test, annot=True, cmap='Greys', xticklabels=['No', 'Yes'], yticklabels=['No', 'Yes'])\n",
    "plt.title('Confusion Matrix for the Test Set')\n",
    "plt.ylabel('True')\n",
    "plt.xlabel('Predicted')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Treinando um GaussianNB com 300 pontos de treinamento. . .\n",
      "O modelo foi treinado em 0.0000 segundos\n",
      "As previsões foram feitas em 0.0000 segundos.\n",
      "Pontuação F1 para o conjunto de treino: 0.8068.\n",
      "As previsões foram feitas em 0.0000 segundos.\n",
      "Pontuação F1 para o conjunto de teste: 0.7669.\n",
      "As previsões foram feitas em 0.0040 segundos.\n",
      "GaussianNB(priors=None)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Text(0.5,28.5,u'Predicted')"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAZAAAAFFCAYAAADCTLtQAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nVWKASJIqMUAkSZUYIJKkSgwQSVIl/x/V3fegx4afnQAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0xf21cba8>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "GNB = GaussianNB()\n",
    "train_predict( GNB, X_train_n, y_train, X_test_n, y_test)\n",
    "print GNB\n",
    "\n",
    "cm_test_b = confusion_matrix(y_test, GNB.predict(X_test))\n",
    "\n",
    "plt.figure(figsize=(7,5))\n",
    "sns.heatmap(cm_test, annot=True, cmap='Greys', xticklabels=['No', 'Yes'], yticklabels=['No', 'Yes'])\n",
    "plt.title('Confusion Matrix for the Test Set')\n",
    "plt.ylabel('True')\n",
    "plt.xlabel('Predicted')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Questão 5 - Pontuação F<sub>1</sub> Final\n",
    "*Qual é a pontuação F<sub>1</sub> do modelo final para treinamento e teste? Como ele se compara ao modelo que não foi calibrado?*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Resposta: ** Como o modelo de Naive Bayes não possui variáveis para calibração, a não ser as probabilidades a priori (que não podem ser buscadas por matriz porque não são variáveis de otimização), não foi possível calibrar o modelo, que teve um F1 score igual a 0,7669. O segundo melhor modelo que retorna probabilidade (Regressão Linear) possui variáveis de otimização que podem ser calibradas, então foi realizada uma busca por matriz nesse modelo. Antes da busca, com os parâmetros em default, o F1 score obtido foi de 0,8050 e após a busca em matriz foi de 0,8079. O resultado da Regressão Logística sem calibração das variáveis obtido anteriormente (apresentado no gráfico de comparação entre os modelos), obteve um score menor do que o não calibrado obtido na célula [50], pois neste último foi realizada uma estratificação dos conjuntos de treino e teste para possuirem a mesma proporção de variáveis alvo e também pois o conjunto de treino foi normalizado, o que melhora o desempenho desse algoritmo."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> **Nota**: Uma vez que você completou todas as implementações de código e respondeu todas as questões acima com êxito, você pode finalizar seu trabalho exportando o iPython Nothebook como um document HTML. Você pode fazer isso utilizando o menu acima e navegando para  \n",
    "**File -> Download as -> HTML (.html)**. Inclua a documentação final junto com o notebook para o envio do seu projeto."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
